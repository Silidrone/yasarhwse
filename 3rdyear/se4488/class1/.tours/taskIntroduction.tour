{
  "id": "3bfb6ad4-617d-46d2-9078-221a12cace16",
  "tourFile": "taskIntroduction.tour",
  "title": "Task Introduction",
  "description": "A New Tour",
  "steps": [
    {
      "title": "K-Armed Bandit Problem",
      "description": "# K-Armed Bandit Problem\nThis is the 10-armed Testbed introduced in \u003cb\u003eSection 2.3\u003c/b\u003e of the textbook. \nThe multiarm bandit machine has 10 arms. Pulling an arm generates a stochastic reward\nfrom a Gaussian distribution with unit-variance. When the machine is reset,\nthe expected values for each action(pulling an arm) are randomly sampled from a normal\ndistribution. If you are unfamiliar with the 10-armed Testbed please review it\nin the textbook before starting this task.\n\u003cbr\u003e\u003cbr\u003e\n\u003cb\u003eSE-4488 Pre-Task-1\nprepared by Dindar Ã–z\u003c/b\u003e"
    },
    {
      "title": "Bandit Machine Interface",
      "description": "# MultirarmBandit Interface\nRepresents any kind of bandit machines(multiarmed or single armed)\nThat can generate a real-valued reward after each roll",
      "file": "MultiArmBandit.java",
      "line": 7
    },
    {
      "title": "Gaussian Bandit Machine",
      "description": "# Gaussian Bandit Machine\nThis particular bandit machine generates rewards randomly with \u003cb\u003eGaussian\u003c/b\u003e distribution",
      "file": "GaussianMAB.java",
      "line": 9
    },
    {
      "title": "Action Selection Methods",
      "description": "Action Selection Methods are represented by \u003cb\u003eActionChooser\u003c/b\u003e interface\n\u003cbr\u003e\u003cbr\u003e\nSome examples:\n* Random Selection\n* Greedy Selection\n* Constant Selection",
      "file": "ActionChooser.java",
      "line": 6
    },
    {
      "title": "Constant Action Selection",
      "description": "A very naive action selection method that selects always the same action",
      "file": "ConstantAC.java",
      "line": 10
    },
    {
      "title": "Bandit Player",
      "description": "Represents the players of the bandit machine.",
      "file": "BanditPlayer.java",
      "line": 6
    },
    {
      "title": "Bandit Player using Reinforcement Learning",
      "description": "Plays the multiarm-bandit machine to maximize the reward by using\n simple reinforcement learning methods (Value estimation \u0026 Action Choosing)\n Those methods are supposed to be implemented as\n\u003cb\u003eValueEstimator\u003c/b\u003e and \u003cb\u003eActionChooser\u003c/b\u003e instances",
      "file": "RLBanditPlayer.java",
      "line": 11
    },
    {
      "title": "Bandit Machine Experiment",
      "description": "The base experiment class for different type of experiments on\nMultiArmBandit machine",
      "file": "BanditExperiment.java",
      "line": 23
    },
    {
      "title": "Start Task",
      "description": "Read and understand the implemented code and complete the tasks given as \u003cb\u003eTODO\u003c/b\u003e items.\nYou can navigate through the todo items in TODO window of your IDE.",
      "file": "RandomAC.java",
      "line": 7
    }
  ]
}